{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPSbhb1U4SZEXNTGOEfFp2v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zmarucheck/EE596/blob/main/Hw1/Part_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZPpNlmpiBpB"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu-iu-Dhipbc",
        "outputId": "1991e7da-e757-4947-8065-e0f4b12b9f3f"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "print(np.shape(x_train))\n",
        "print(np.shape(y_train))\n",
        "\n",
        "# Preprocess the data (these are NumPy arrays)\n",
        "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
        "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
        "\n",
        "y_train = y_train.astype(\"float32\")\n",
        "y_test = y_test.astype(\"float32\")\n",
        "\n",
        "# Reserve 10,000 samples for validation\n",
        "x_val = x_train[-10000:]\n",
        "y_val = y_train[-10000:]\n",
        "x_train = x_train[:-10000]\n",
        "y_train = y_train[:-10000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J0hZPszjsed"
      },
      "source": [
        "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
        "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
        "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
        "x = layers.Dense(64, activation=\"relu\", name=\"dense_3\")(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoW5mdtXjWcF"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(0.001),  # Optimizer\n",
        "    # Loss function to minimize\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    # List of metrics to monitor\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CwiKq-djpZL",
        "outputId": "61bee6d9-5ce9-42e9-fce9-aed10641f42d"
      },
      "source": [
        "print(\"Fit model on training data\")\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=128,\n",
        "    epochs=10,\n",
        "    validation_data=(x_val, y_val),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit model on training data\n",
            "Epoch 1/10\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.0709 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.2204 - val_sparse_categorical_accuracy: 0.9746\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0528 - sparse_categorical_accuracy: 0.9854 - val_loss: 0.2305 - val_sparse_categorical_accuracy: 0.9744\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0478 - sparse_categorical_accuracy: 0.9869 - val_loss: 0.2641 - val_sparse_categorical_accuracy: 0.9755\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0425 - sparse_categorical_accuracy: 0.9881 - val_loss: 0.2617 - val_sparse_categorical_accuracy: 0.9747\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0394 - sparse_categorical_accuracy: 0.9888 - val_loss: 0.2683 - val_sparse_categorical_accuracy: 0.9763\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0363 - sparse_categorical_accuracy: 0.9892 - val_loss: 0.2913 - val_sparse_categorical_accuracy: 0.9759\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0352 - sparse_categorical_accuracy: 0.9900 - val_loss: 0.2893 - val_sparse_categorical_accuracy: 0.9752\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0329 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.3325 - val_sparse_categorical_accuracy: 0.9758\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0298 - sparse_categorical_accuracy: 0.9914 - val_loss: 0.3629 - val_sparse_categorical_accuracy: 0.9747\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0277 - sparse_categorical_accuracy: 0.9917 - val_loss: 0.3782 - val_sparse_categorical_accuracy: 0.9751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYAS0cHBkDtC"
      },
      "source": [
        "Among the different parameters,\n",
        "you can vary the learning rate, activation functions, number of neurons, number of layers, number of epochs,\n",
        "batch size, etc. Make a table of your investigations and the performances of the different settings. Explain\n",
        "\n",
        "| Trial | Learning Rate | Activation function | Number of neurons | Number of Layers | Number of epochs | Ending Loss | Ending Accuracy |\n",
        "|-|-|-|-|-|-|-|-|\n",
        "| 1 | 0.001 | relu | 64 | 2 | 10 | 0.0067 | 0.9980 |\n",
        "| 2 | 0.001 | relu | 64 | 2 | 2 | 0.0180 | 0.9946 |\n",
        "| 3 | 0.01 | relu | 64 | 2 | 10 | 0.1131 | 0.9757 |\n",
        "| 4 | 0.001 | relu | 64 | 3 | 10 | 0.0277 | 0.9917 |\n",
        "\n",
        "T1) Arbitrarily the base case.  \n",
        "T2) Lower epoch number increases the loss while decreasing the accuracy, but increasing the epoch doesn't significantly help after a certain point.  \n",
        "T3) Learning rate of 0.01 caused the loss to bounce around 0.115 rather than continue lessening at a steady pace.  \n",
        "T4) Adding an additional layer increased the loss while lowering the accuracy slightly from the base case.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaH5tWQIjyg0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}